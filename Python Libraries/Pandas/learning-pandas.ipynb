{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"language = ['C', 'C++', 'Java', 'Python', 'R', 'Go', 'Haskell', 'Scala', 'JavaScript']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"language = pd.Series(language) # series is a 1D labelled array \nprint (language)\nprint (type(language))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"language[4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.Series(language, index = ['a','b','c', 'd', 'e', 'f', 'g', 'h', 'i'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"language.index = ['a','b','c', 'd', 'e', 'f', 'g', 'h', 'i'] # index the elements as you like\nprint (language) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"language['c']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **DataFrames**\n## -- A collection of series","metadata":{}},{"cell_type":"code","source":"arr = np.random.randint(10, 100, (6,4))\narr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data = arr)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(df[2]) # it is a series","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns = ['A', 'B', 'C', 'D']\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['B', 'D']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head() # will return the first five rows ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3) # 5 is the default value, however it can be set to any other value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail() # returns the last 5 rows by default","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['A+B'] = df['A'] + df['B'] # creates a new column A+B with sum of values of column A and B\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns = ['D']) # deletes the column D","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.index = \"p q r s t u\".split()\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc['p'] # loc is used to extract a row","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[4] # integer location of the row - here t is at position 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc['q': 't'][['B', 'C']] # indexes from start_row_index to last_row_index - 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[-2:][['D', 'A+B']] # returns the last 4 corner cells of the array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = df['B'] > 40\nmask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[mask] # as B value for row q, r and s is False, they are dropped from the dataframe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Iris Dataset","metadata":{}},{"cell_type":"markdown","source":"**Click on +Add Data to upload the data file from your device**","metadata":{}},{"cell_type":"markdown","source":"To get the file path:\n1. click on the drop down arrow beside **Data**\n2. copy the file path of the file from the **Input** section\n\n[Read this notebook for more help](https://www.kaggle.com/code/dansbecker/finding-your-files-in-kaggle-kernels/notebook)","metadata":{}},{"cell_type":"code","source":"iris = pd.read_csv('../input/iris-dataset/iris.csv') # syntax to read the file\niris","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris['species'].nunique() # returns the number of unique values in that column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris['species'].unique() # returns the unique values  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris[iris['species'] == 'versicolor'].shape # filters out the versicolor species and counts them","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris['species'].value_counts() # returns the counts of each unique value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris['species'].value_counts()['virginica'] # to get the count of a specific value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(iris['petal_length'].max())\nprint(iris['petal_length'].min())\nprint(iris['petal_length'].sum())\nprint(iris['petal_length'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris.sort_values(by = 'petal_length') # arranged in increasing order by the petal length","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris.sort_values(by = ['petal_length', 'sepal_length']) \n# if petal_length is same, it is arranged in increasing order acc. to the sepal_length","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris['species'].apply(lambda x: x + x) # applies the given function to the entire column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"iris.aggregate(['min', 'max']) # returns the min and max values of all the fields","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped = iris.groupby('species')\ngrouped","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped.min() # returns the minimum value of each field for each unique species","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris2 = pd.read_csv('../input/iris-dataset/iris.csv')\niris2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#deleting values from the dataset\nnan_idx = np.random.randint(0, 150, 20) # randomly picks 20 indices\niris2['sepal_length'][nan_idx] = np.nan # replaces them with NaN (not a number)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris2['sepal_length'][:50] # voids have been created","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris2.isna().sum() # isna checks for NaN values in the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uncomment the next comment to test it\n# iris.dropna() \n# dropna drops the rows with any NaN values\n#not recommended","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round (iris2['sepal_length'].mean(), 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iris2['sepal_length'].fillna(round (iris2['sepal_length'].mean(), 1)) \n# fillna repalces all NaN values with the value you provide\n# here, it is replaced by the mean","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"# creating new dataset\ndummy_iris = pd.DataFrame(np.random.randint(0, 7, (10,4)))\ndummy_iris","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating species\ndummy_iris['species'] = \"new-species\"\ndummy_iris","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy_iris.columns = iris.columns # assigning the iris column names to dummy_iris \ndummy_iris","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_iris = pd.concat((iris, dummy_iris)) # axis = 1 for concatenating row wise \nnew_iris","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame({'Student': ['Nikhil', 'Roshan', 'Sayantan', 'Shadab'],\n                   'Marks': [12, 23, 34, 45]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame({'Teacher': ['KGT', 'ABC', 'AGD', 'SPR'],\n                   'Marks': [34, 56, 45, 67]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.merge(df2, how = 'inner') \n# matches the value according to the common field and prints the common ones","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.merge(df2, how = 'outer')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.merge(df2, how = 'left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.merge(df2, how = 'right')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n**Saving files**","metadata":{}},{"cell_type":"code","source":"new_iris.to_csv('./new_iris.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}